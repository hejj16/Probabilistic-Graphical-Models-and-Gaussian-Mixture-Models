# Probabilistic Graphical Models: Notes and Examples

This repository summaries basic principles and technologies in Probabilistic Graphical Models and uses Gaussian Mixture Models as an example to illustrate these basic ideas.


**This repository contains**:

- Notes on Probabilistic Graphical Models: 
  - [Representation](https://github.com/hejj16/Probabilistic-Graphical-Models-and-Gaussian-Mixture-Models/blob/main/PGM-Notes/PGM-Representation-notes.pdf)
  - [Inference](https://github.com/hejj16/Probabilistic-Graphical-Models-and-Gaussian-Mixture-Models/blob/main/PGM-Notes/PGM-Inference-notes.pdf)
  - [Learning](https://github.com/hejj16/Probabilistic-Graphical-Models-and-Gaussian-Mixture-Models/blob/main/PGM-Notes/PGM-Learning-notes.pdf)
- An overview of Gaussian Mixture Models from the perspective of Probabilistic Graphical Models
- Inference or Learning Methods in Gaussian Mixture Models
  - EM Algorithm
    - Theoretical Derivation
    - Python Codes
  - Mean Field Variational Inference (Coordinate Ascending VI)
    - [Theoretical Derivation](https://github.com/hejj16/Probabilistic-Graphical-Models-and-Gaussian-Mixture-Models/blob/main/Theoretical_Derivation/GMM_MFVI.pdf)
    - [Python Codes](https://github.com/hejj16/Probabilistic-Graphical-Models-and-Gaussian-Mixture-Models/blob/main/Codes/GMM_MFVI.py)
  - MCMC: Gibbs Sampling
    - Theoretical Derivation
    - [Python Codes](https://github.com/hejj16/Probabilistic-Graphical-Models-and-Gaussian-Mixture-Models/blob/main/Codes/GMM_GibbsSampling.py)
  - MCMC: Metropolis-Hastings Sampling
    - Theoretical Derivation
    - [Python Codes](https://github.com/hejj16/Probabilistic-Graphical-Models-and-Gaussian-Mixture-Models/blob/main/Codes/GMM_MHSampling.py)
  - MCMC: Hamiltonian Monte Carlo
    - Theoretical Derivation
    - Python Codes
  - ...
  
  
  
    

**Updating On Going...**
